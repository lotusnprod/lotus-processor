{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch ClassyFirer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building on pyMolNetEnhancer (https://pypi.org/project/pyMolNetEnhancer/) this notebook allows to fetch classyfire for large structure tables.\n",
    "The main mnodification concern the ability to fetch classyfire results for inchi (or smiles) based input. \n",
    "The paginated JSON results are fetched using the xxxxx function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load libraries required by pyMolNetEnhancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybatchclassyfire import *\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv \n",
    "import time\n",
    "import json\n",
    "from pandas import json_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set option for display in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.reset_option('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_rows', 40)\n",
    "pd.set_option('max_columns', 40)\n",
    "#pd.set_option('display.max_colwidth', 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opendb = pd.read_csv(\"/Users/pma/Downloads/open_NP_db_sanitized.tsv\", sep = \"\\t\")\n",
    "opendb = pd.read_csv(\"../../opennaturalproductsdb/outputs/tables/3_curated/curated_structure_min.tsv\", \n",
    "                     sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicates are droped at the sanitized inchi columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "opendb.drop_duplicates('inchikey_sanitized', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment if a minimal input is needed for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#opendb = opendb.head(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch info on the loaded df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4253 entries, 0 to 4274\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   structure_translated  4253 non-null   object \n",
      " 1   validator_log         4253 non-null   object \n",
      " 2   smiles_sanitized      4253 non-null   object \n",
      " 3   inchi_sanitized       4253 non-null   object \n",
      " 4   inchikey_sanitized    4253 non-null   object \n",
      " 5   shortik_sanitized     4253 non-null   object \n",
      " 6   formula_sanitized     4253 non-null   object \n",
      " 7   exactmass_sanitized   4253 non-null   float64\n",
      " 8   xlogp_sanitized       4253 non-null   float64\n",
      " 9   structure_sanitized   4253 non-null   object \n",
      " 10  structure_curated     4248 non-null   object \n",
      "dtypes: float64(2), object(9)\n",
      "memory usage: 398.7+ KB\n"
     ]
    }
   ],
   "source": [
    "opendb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>structure_translated</th>\n",
       "      <th>validator_log</th>\n",
       "      <th>smiles_sanitized</th>\n",
       "      <th>inchi_sanitized</th>\n",
       "      <th>inchikey_sanitized</th>\n",
       "      <th>shortik_sanitized</th>\n",
       "      <th>formula_sanitized</th>\n",
       "      <th>exactmass_sanitized</th>\n",
       "      <th>xlogp_sanitized</th>\n",
       "      <th>structure_sanitized</th>\n",
       "      <th>structure_curated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>InChI=1S/C16H26/c1-12(2)14-8-10-15(4)9-6-7-13(...</td>\n",
       "      <td>[]</td>\n",
       "      <td>C=C(C)C1CCC2(C)CCC=C(C)[C@@]2(C)C1</td>\n",
       "      <td>InChI=1S/C16H26/c1-12(2)14-8-10-15(4)9-6-7-13(...</td>\n",
       "      <td>IGHNHLWYXDJPIB-UYSNPLJNSA-N</td>\n",
       "      <td>IGHNHLWYXDJPIB</td>\n",
       "      <td>C16H26</td>\n",
       "      <td>218.203451</td>\n",
       "      <td>5.11530</td>\n",
       "      <td>InChI=1S/C16H26/c1-12(2)14-8-10-15(4)9-6-7-13(...</td>\n",
       "      <td>InChI=1S/C16H26/c1-12(2)14-8-10-15(4)9-6-7-13(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>InChI=1S/C19H19N7O6/c20-19-25-15-14(17(30)26-1...</td>\n",
       "      <td>[]</td>\n",
       "      <td>N=c1nc(O)c2nc(CNc3ccc(C(=O)N[C@@H](CCC(=O)O)C(...</td>\n",
       "      <td>InChI=1S/C19H19N7O6/c20-19-25-15-14(17(30)26-1...</td>\n",
       "      <td>OVBPIULPVIDEAO-LBPRGKRZSA-N</td>\n",
       "      <td>OVBPIULPVIDEAO</td>\n",
       "      <td>C19H19N7O6</td>\n",
       "      <td>441.139681</td>\n",
       "      <td>0.19787</td>\n",
       "      <td>InChI=1S/C19H19N7O6/c20-19-25-15-14(17(30)26-1...</td>\n",
       "      <td>InChI=1S/C19H19N7O6/c20-19-25-15-14(17(30)26-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>InChI=1S/C22H33NO/c1-3-4-5-6-7-8-9-10-11-12-15...</td>\n",
       "      <td>[]</td>\n",
       "      <td>CCCCCCCCCCCCc1cc(=O)c2ccccc2n1C</td>\n",
       "      <td>InChI=1S/C22H33NO/c1-3-4-5-6-7-8-9-10-11-12-15...</td>\n",
       "      <td>URTNWZJTIJSNON-UHFFFAOYSA-N</td>\n",
       "      <td>URTNWZJTIJSNON</td>\n",
       "      <td>C22H33NO</td>\n",
       "      <td>327.256215</td>\n",
       "      <td>6.00190</td>\n",
       "      <td>InChI=1S/C22H33NO/c1-3-4-5-6-7-8-9-10-11-12-15...</td>\n",
       "      <td>InChI=1S/C22H33NO/c1-3-4-5-6-7-8-9-10-11-12-15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>InChI=1S/C9H13NO3/c1-10-5-9(13)6-2-3-7(11)8(12...</td>\n",
       "      <td>[]</td>\n",
       "      <td>CNC[C@H](O)c1ccc(O)c(O)c1</td>\n",
       "      <td>InChI=1S/C9H13NO3/c1-10-5-9(13)6-2-3-7(11)8(12...</td>\n",
       "      <td>UCTWMZQNUQWSLP-VIFPVBQESA-N</td>\n",
       "      <td>UCTWMZQNUQWSLP</td>\n",
       "      <td>C9H13NO3</td>\n",
       "      <td>183.089543</td>\n",
       "      <td>0.35060</td>\n",
       "      <td>InChI=1S/C9H13NO3/c1-10-5-9(13)6-2-3-7(11)8(12...</td>\n",
       "      <td>InChI=1S/C9H13NO3/c1-10-5-9(13)6-2-3-7(11)8(12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>InChI=1S/C18H34O5/c1-2-3-4-8-11-16(20)17(21)14...</td>\n",
       "      <td>[]</td>\n",
       "      <td>CCCCCCC(O)C(O)/C=C/C(O)CCCCCCC(=O)O</td>\n",
       "      <td>InChI=1S/C18H34O5/c1-2-3-4-8-11-16(20)17(21)14...</td>\n",
       "      <td>YFCZLXRIKFCQFU-BUHFOSPRSA-N</td>\n",
       "      <td>YFCZLXRIKFCQFU</td>\n",
       "      <td>C18H34O5</td>\n",
       "      <td>330.240624</td>\n",
       "      <td>3.02090</td>\n",
       "      <td>InChI=1S/C18H34O5/c1-2-3-4-8-11-16(20)17(21)14...</td>\n",
       "      <td>InChI=1S/C18H34O5/c1-2-3-4-8-11-16(20)17(21)14...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                structure_translated validator_log  \\\n",
       "0  InChI=1S/C16H26/c1-12(2)14-8-10-15(4)9-6-7-13(...            []   \n",
       "1  InChI=1S/C19H19N7O6/c20-19-25-15-14(17(30)26-1...            []   \n",
       "2  InChI=1S/C22H33NO/c1-3-4-5-6-7-8-9-10-11-12-15...            []   \n",
       "3  InChI=1S/C9H13NO3/c1-10-5-9(13)6-2-3-7(11)8(12...            []   \n",
       "4  InChI=1S/C18H34O5/c1-2-3-4-8-11-16(20)17(21)14...            []   \n",
       "\n",
       "                                    smiles_sanitized  \\\n",
       "0                 C=C(C)C1CCC2(C)CCC=C(C)[C@@]2(C)C1   \n",
       "1  N=c1nc(O)c2nc(CNc3ccc(C(=O)N[C@@H](CCC(=O)O)C(...   \n",
       "2                    CCCCCCCCCCCCc1cc(=O)c2ccccc2n1C   \n",
       "3                          CNC[C@H](O)c1ccc(O)c(O)c1   \n",
       "4                CCCCCCC(O)C(O)/C=C/C(O)CCCCCCC(=O)O   \n",
       "\n",
       "                                     inchi_sanitized  \\\n",
       "0  InChI=1S/C16H26/c1-12(2)14-8-10-15(4)9-6-7-13(...   \n",
       "1  InChI=1S/C19H19N7O6/c20-19-25-15-14(17(30)26-1...   \n",
       "2  InChI=1S/C22H33NO/c1-3-4-5-6-7-8-9-10-11-12-15...   \n",
       "3  InChI=1S/C9H13NO3/c1-10-5-9(13)6-2-3-7(11)8(12...   \n",
       "4  InChI=1S/C18H34O5/c1-2-3-4-8-11-16(20)17(21)14...   \n",
       "\n",
       "            inchikey_sanitized shortik_sanitized formula_sanitized  \\\n",
       "0  IGHNHLWYXDJPIB-UYSNPLJNSA-N    IGHNHLWYXDJPIB            C16H26   \n",
       "1  OVBPIULPVIDEAO-LBPRGKRZSA-N    OVBPIULPVIDEAO        C19H19N7O6   \n",
       "2  URTNWZJTIJSNON-UHFFFAOYSA-N    URTNWZJTIJSNON          C22H33NO   \n",
       "3  UCTWMZQNUQWSLP-VIFPVBQESA-N    UCTWMZQNUQWSLP          C9H13NO3   \n",
       "4  YFCZLXRIKFCQFU-BUHFOSPRSA-N    YFCZLXRIKFCQFU          C18H34O5   \n",
       "\n",
       "   exactmass_sanitized  xlogp_sanitized  \\\n",
       "0           218.203451          5.11530   \n",
       "1           441.139681          0.19787   \n",
       "2           327.256215          6.00190   \n",
       "3           183.089543          0.35060   \n",
       "4           330.240624          3.02090   \n",
       "\n",
       "                                 structure_sanitized  \\\n",
       "0  InChI=1S/C16H26/c1-12(2)14-8-10-15(4)9-6-7-13(...   \n",
       "1  InChI=1S/C19H19N7O6/c20-19-25-15-14(17(30)26-1...   \n",
       "2  InChI=1S/C22H33NO/c1-3-4-5-6-7-8-9-10-11-12-15...   \n",
       "3  InChI=1S/C9H13NO3/c1-10-5-9(13)6-2-3-7(11)8(12...   \n",
       "4  InChI=1S/C18H34O5/c1-2-3-4-8-11-16(20)17(21)14...   \n",
       "\n",
       "                                   structure_curated  \n",
       "0  InChI=1S/C16H26/c1-12(2)14-8-10-15(4)9-6-7-13(...  \n",
       "1  InChI=1S/C19H19N7O6/c20-19-25-15-14(17(30)26-1...  \n",
       "2  InChI=1S/C22H33NO/c1-3-4-5-6-7-8-9-10-11-12-15...  \n",
       "3  InChI=1S/C9H13NO3/c1-10-5-9(13)6-2-3-7(11)8(12...  \n",
       "4  InChI=1S/C18H34O5/c1-2-3-4-8-11-16(20)17(21)14...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opendb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve ClassyFire classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first step is done using inchikey and interrogation of the gnps classified structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnps_proxy = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://classyfire.wishartlab.com\"\n",
    "proxy_url =  \"https://gnps-classyfire.ucsd.edu\"\n",
    "chunk_size = 1000\n",
    "sleep_interval = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a slightly modified version of the original get_classification() which will take list object as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The while loop below allows to run the get_classifications() function until the number of classified inchikey stablizes. Indeed, it has been observed that when running the get_classifications() multiple times the number of classified structures was different. Since the requests are stocked in the .sqlite file implemenmting the while loop allows to fetch the maximum of structures by iterations.\n",
    "The reason why the get_classifications() is not directly returning the maximal number of classified structures is unknown. It might be due to GET request errors which remain silent because of the parralelization of the function ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4253 inchikey to resolve\n",
      "4224 resolved inchikeys\n",
      "done in --- 32.12632703781128 seconds ---\n",
      "4253 inchikey to resolve\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-18200808d5fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s inchikey to resolve'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtotal_inchikey_number\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mget_classifications_cf_mod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_inchi_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mcleanse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all_json.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'all_json.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/my-rdkit-env/lib/python3.7/site-packages/pybatchclassyfire/pybatchclassyfire.py\u001b[0m in \u001b[0;36mget_classifications_cf_mod\u001b[0;34m(all_inchi_keys)\u001b[0m\n\u001b[1;32m    534\u001b[0m     \"\"\"\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m     \u001b[0mall_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_parallel_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_structure_class_entity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_inchi_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallelism_level\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"all_json.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/my-rdkit-env/lib/python3.7/site-packages/pybatchclassyfire/pybatchclassyfire.py\u001b[0m in \u001b[0;36mrun_parallel_job\u001b[0;34m(input_function, input_parameters_list, parallelism_level)\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput_results_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallelism_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_object\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput_object\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_parameters_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/my-rdkit-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/my-rdkit-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/my-rdkit-env/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/my-rdkit-env/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/my-rdkit-env/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_inchi_keys = list(opendb['inchikey_sanitized'].drop_duplicates())\n",
    "\n",
    "resolved_ik_number_list = [0, 0]\n",
    "total_inchikey_number = len(all_inchi_keys)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    print('%s inchikey to resolve' % total_inchikey_number )\n",
    "    get_classifications_cf_mod(all_inchi_keys)\n",
    "    \n",
    "    cleanse('all_json.json', 'all_json.json')\n",
    "    \n",
    "    with open(\"all_json.json\") as tweetfile:\n",
    "        jsondic = json.loads(tweetfile.read())\n",
    "\n",
    "    df = json_normalize(jsondic)\n",
    "    df = df.drop_duplicates( 'inchikey' )\n",
    "    resolved_ik_number = len( df.drop_duplicates('inchikey').inchikey )\n",
    "    resolved_ik_number_list.append( resolved_ik_number )\n",
    "    print('%s resolved inchikeys' % resolved_ik_number )\n",
    "    print(\"done in --- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    if resolved_ik_number_list[-1] < resolved_ik_number_list[-2] or resolved_ik_number_list[-1] == resolved_ik_number_list[-3]:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the cleanse function to directly remove unclassified structures from the json. Else the json file is not treated by the json_normalize() function.\n",
    "To remove null entries from json inputs and output cleaned file we define the cleanse() function. Slightly adapted from https://stackoverflow.com/a/50531943"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanse('all_json.json', 'all_json_cleaned.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load this cleaned json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_json_cleaned.json\") as tweetfile:\n",
    "        jsondic = json.loads(tweetfile.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And normalize the output as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_classified_json = json_normalize(jsondic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And have a peak into this new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flattened_classified_json.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_classified_json.drop_duplicates('inchikey').info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to output the unclassified IK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So first we strip the InChI= prefix of the previously returned df and keep it as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "+41 22 312 45 20classified_ik_list = list(flattened_classified_json['inchikey'].str.replace(r'InChIKey=', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now make the difference between the inputed ik list and the classified ik list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(all_inchi_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(classified_ik_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(set(all_inchi_keys) - set(classified_ik_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the CF output with the original DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_df = flattened_classified_json.drop_duplicates('inchikey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_df['inchikey'] = flattened_df['inchikey'].str.replace(r'InChIKey=', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(opendb,\n",
    "                     flattened_df, \n",
    "                     left_on = 'inchikey_sanitized',\n",
    "                     right_on = 'inchikey',\n",
    "                     how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_unclassed = df_merged[df_merged['inchikey'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_unclassed.drop_duplicates('inchi_sanitized', \n",
    "                                    inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_unclassed.to_csv('test_datatable_unclassed.tsv',\n",
    "                           sep = '\\t', \n",
    "                           encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classyfing the unclassified by inchi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a modified version of the tabular_query() function which basically just launches a structure_query for all inchi or smile at a given column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "query_ids = batch_query('test_datatable_unclassed.tsv',\n",
    "                        'inchi_sanitized',\n",
    "                        dialect = 'excel-tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The status can also be checked manually at the following adress (just change the query id)\n",
    "http://classyfire.wishartlab.com/queries/3879356.json?page=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These settings of the request_cache allow to retry when 429 (or other) type of errors are returned by the classyfire server. Most of the time when too many intents are made. Since this seems to be a random behaviour, fixing a time.sleep is not safe enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "open(\"test_datatable_result_inchi.json\", \"w\").write(json.dumps(Etienne-Dumont, 9get_results_multientry_multipage_patient(query_ids,\n",
    "                                                                                                        return_format = \"json\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs standardization \n",
    "\n",
    "Now we will standardize the json output of classifire gent_entity() and the one of get_results_multipage_patient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the cleanse() function which as been previously defined to remove null entries from the json and normalize it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For round 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the output of the get_results_multipage_patient() we first load the json as a dataframe and remove identities with an empty identifier value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_datatable_result_inchi.json\") as tweetfile:\n",
    "    jsondic_inchi = json.loads(tweetfile.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The json_normalize function is used to flatten the nested JSON structure.\n",
    "Beware here the meta = ['id'] field can sometimes return an error. Remove if you dont need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df_inchi = json_normalize(jsondic_inchi,\n",
    "                                     record_path = 'entities',\n",
    "                                     meta = ['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df_inchi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we remove rows for wich no identifier is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df_inchi_nona = normalized_df_inchi[normalized_df_inchi['identifier'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the previous df is outputed ad a json file using the 'records' option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df_inchi_nona.to_json(r'result_json_all_cleaned.json', \n",
    "                                 orient = 'records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging both outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_classified_json.inchikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [flattened_classified_json, normalized_df_inchi_nona]\n",
    "\n",
    "result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.drop_duplicates('inchikey').info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting df can be exported as JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_json(r'results_full.json',\n",
    "               orient = 'records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file can be reloaded for further expansion of nested fields (to pursue later on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results_full.json\") as tweetfile:\n",
    "    jsondic = json.loads(tweetfile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df = json_normalize(jsondic,\n",
    "                               record_path = 'intermediate_nodes',\n",
    "                               meta = ['inchikey']\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " normalized_df = json_normalize(jsondic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normalized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we will select fields of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the total json and we normailze it as a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results_full.json\") as tweetfile:\n",
    "    jsondic = json.loads(tweetfile.read())\n",
    "    normalized_df = json_normalize(jsondic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normalized_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We here make a list of unwanted coloumns name and we drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colstodrop = ['smiles', 'intermediate_nodes', 'alternative_parents',\n",
    "       'molecular_framework', 'substituents', 'description',\n",
    "       'external_descriptors', 'ancestors', 'predicted_chebi_terms',\n",
    "       'predicted_lipidmaps_terms', 'classification_version', \n",
    "       'kingdom.description', 'kingdom.chemont_id', 'kingdom.url',\n",
    "        'superclass.description', 'superclass.chemont_id',\n",
    "       'superclass.url',  'class.description', 'class.chemont_id',\n",
    "       'class.url',  'subclass.description',\n",
    "       'subclass.chemont_id', 'subclass.url', \n",
    "       'direct_parent.description', 'direct_parent.chemont_id',\n",
    "       'direct_parent.url', 'identifier', 'subclass', 'label']\n",
    "\n",
    "normalized_df.drop(colstodrop,\n",
    "                   axis = 1,\n",
    "                   inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normalized_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normalized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normalized_df.drop_duplicates('inchikey').info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we merge this classified df with the original df (after making sure bothe have been deduplicated and the InChIKey= string as been appended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opendb.drop_duplicates('inchi_sanitized', \n",
    "                       inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df['inchikey'] = normalized_df['inchikey'].str.replace(r'InChIKey=', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_classy = pd.merge(opendb,\n",
    "                           normalized_df, \n",
    "                           left_on = 'inchikey_sanitized', \n",
    "                           right_on = 'inchikey',\n",
    "                           how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final_classy.drop_duplicates('inchikey_sanitized').info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_classy.to_csv('final_classy.tsv', \n",
    "                       sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
